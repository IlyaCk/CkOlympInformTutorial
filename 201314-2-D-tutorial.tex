\Tutorial	
Очевидний підхід\nolinebreak[3] --- бр\'{а}ти кожне число \mbox{1-го} рядка, і шукати його в\nolinebreak[3] усіх інших рядках. Якщо знайдене в\nolinebreak[3] усіх\nolinebreak[3] --- поточне число слід включити у\nolinebreak[3] відповідь (а\nolinebreak[3] якщо\nolinebreak[2] ні, то\nolinebreak[3] ні).
І\nolinebreak[3] цей підхід \emph{може} бути правильним. Але\nolinebreak[2] \emph{залежно} від того, чи\nolinebreak[3] реалізувати його наївно, чи\nolinebreak[3] ефективно. 

Наївний підхід полягає у\nolinebreak[3] т\'{о}му, щоб для пошуку кожного числ\'{а} в кожному рядку запускати свій цикл, переглядаючи увесь рядок. Але такий розв'язок потребує $O(N{\cdot}M^2)$, що може не\nolinebreak[3] поміщатися у обмеження часу. Власне, $1234^3\dib{{\approx}}{1{,}88{\cdot}10^9}$ простих порівнянь на\nolinebreak[2] потужнішому сервері цілком могло~б і поміститися у\nolinebreak[3] 3~сек. Але в\nolinebreak[3] тому й смисл задачі, щоб реалізувати щось ефективніше, і\nolinebreak[3] на\nolinebreak[3] потужнішому сервері просто ставили~б жорсткіший time\nolinebreak[2] limit. А\nolinebreak[3] такий розв'язок благополучно отримує свої 40\nolinebreak[3] балів зі~100. 

\MyParagraph{Правильний розв'язок $\No\,$1}
Той самий підхід можна реалізувати ефективніше завдяки тому, що кожен рядок гарантовано впорядкований. Адже для впорядкованих масивів можливий \emph{бінарний пошук} (скорочено <<\emph{бінпошук}>>, він\nolinebreak[3] же <<\emph{двійковий пошук}>>, він\nolinebreak[3] же <<\emph{дихотомія}>>). Суть бінпошуку така: коли треба знайти значення, починають з\nolinebreak[3] середнього (за\nolinebreak[3] індексом) елемента; якщо (раптом) він якраз рівний шуканому значенню, пошук успішно завершений; якщо шукане значення більше за\nolinebreak[3] середній елемент, то\nolinebreak[3] можна відкинути усю ліву половину масиву, а\nolinebreak[3] якщо менше\nolinebreak[3] --- усю праву половину. На\nolinebreak[3] наступному кроці (якщо він взагалі потрібен) робиться те\nolinebreak[3] с\'{а}ме, але з тією половиною, що залишилась. І\nolinebreak[3] так далі. Тобто, за одне порівняння завжди можна відкинути щонайменше половину масиву, і пошук у масиві з 1234 елементами потребує до ${\approx}11$\nolinebreak[3] порівнянь, а\nolinebreak[3] асимптотично\nolinebreak[3] --- $O(\log{}M)$. А\nolinebreak[3] $N{\cdot}M$\nolinebreak[2] штук \emph{таких} пошуків чудово поміщаються у обмеження. 

Рекомендується знайти в\nolinebreak[3] Інтернеті або літературі додаткові деталі щодо бін\-пошуку. Бо\nolinebreak[3] це такий алгоритм, у\nolinebreak[3] якому, навіть добре знаючи загальну ідею, легко помил\'{и}тися й отримати код, який часто працює правильно, але іноді зациклюється або/та видає неправильні результати. 

Тим, хто пише мовою\nolinebreak[3] C++, рекомендується вивчити, як у\nolinebreak[3] деяких ситуаціях (включно з цією задачею) можна не\nolinebreak[3] писати бін\-пошук самому, якщо навчитися правильно користуватися функцією \verb"lower_bound" бібліотеки\nolinebreak[2] \texttt{algorithm}.


\MyParagraph{Правильний розв'язок $\No\,$2}
Ще один правильний розв'язок (із\nolinebreak[2] \emph{кращою} асимптотичною оцінкою $O(N{\cdot}M)$ проти $O(N{\cdot}M{\cdot}\log{}M)$ у\nolinebreak[3] попереднього; але ловити цю відмінність за часом роб\'{о}ти програми не~дуже реально, тому попередній розв'язок теж вважається ефективним)\nolinebreak[3] --- багатократно застосовувати модифікацію \emph{злиття} (рос.\nolinebreak[3] <<\emph{слияние}>>, англ.\nolinebreak[3] <<\emph{merge}>>). 

Суть стандартного злиття така. Нехай є дві (\emph{обов'язково впорядковані!}) послідовності (зазвичай два масиви або два фрагменти одного масиву, але можуть бути й інші послідовності, як-то файли чи зв'язні списки). З~них можна легко й швидко сформувати впорядковану послі\-дов\-ність-від\-повідь, куди входять усі елемети обох заданих послідовностей, якщо діяти так. Призначаємо кожній зі вхідних послідовностей поточну позицію як початок цієї послідовності. І\nolinebreak[3] повторюємо у\nolinebreak[3] циклі такі дії: (1)~беремо (пишемо у послі\-дов\-ність-від\-по\-відь) менший з поточних елементів послідовностей; (2)~зсуваємо поточну позицію тієї вхідної послідовності (\emph{лише однієї з двох!}), звідки взятий цей менший елемент. Коли одна з послідовностей закінчується, дописуємо у послі\-дов\-ність-від\-по\-відь увесь ще\nolinebreak[3] не\nolinebreak[3] використаний <<хвіст>> іншої послідовності. Це\nolinebreak[3] --- \emph{стандартне} злиття, яке робить те\nolinebreak[3] саме (але\nolinebreak[3] швидше), що дописування однієї з послідовностей після іншої та сортування всього разом. Очевидно, воно працює за час $O(l_1{+}l_2)$ (де\nolinebreak[3] $l_1$\nolinebreak[1] та\nolinebreak[3] $l_2$\nolinebreak[3] --- довж\'{и}ни вхідних послідовностей).

У\nolinebreak[3] даній задачі треба інше (спільні елементи). Але, виявляється, під цю задачу теж легко модифікувати злиття. Треба лише при порівнянні поточних елементів різних послідовностей розрізняти три випадки: якщо поточний елемент \mbox{1-ої} послідовності строго менший за поточний елемент \mbox{2-ої}, то зсунути поточну позицію \mbox{1-ої} послідовності (нічого не~пишучи у~відповідь); якщо строго більший, то зсунути позицію \mbox{2-ої} послідовності (теж не~пишучи); якщо поточні елементи рівні, то записати це однакове (спільне) значення у результат та зсунути поточні позиції обох послідовностей. Само собою, при завершенні однієї з послідовностей треба \emph{не}~дописувати <<хвіст>> іншої. Час роботи такого модифікату злиття теж $O(l_1{+}l_2)$.

Зрештою, це\nolinebreak[3] --- злиття \emph{двох} послідовностей; пропонується першого разу злити \mbox{1-ий} рядок з \mbox{2-им}, а\nolinebreak[3] потім зливати з кожним черговим (\mbox{3-ім},\nolinebreak[2] \mbox{4-им},~\dots) результат попереднього злиття. \emph{Завдяки} тому, що завжди вибираються лише спільні елементи, розмір кожної з цих послідовностей${}\<M$, тому ${N{-}1}\dib{{=}}O(N)$ застосувань злиття забирають час $O(N{\cdot}M)$. (\emph{Якби} робилося стандартне злиття і розміри послідовностей зростали, оцінка була~б значно більшою).
% % % : при розглянутому підході\nolinebreak[3] --- $\theta(N^2{\cdot}M)$, 
% % % при більш збалансованих злиттях\nolinebreak[3] --- $\theta(N{\cdot}M{\cdot}\log{}N)$).

Бажано знайти в\nolinebreak[3] Інтернеті або літературі якусь додаткову інформацію про злиття. Її\nolinebreak[2] з~одного боку достатньо, але\nolinebreak[2] з~іншого\nolinebreak[3] --- надто часто пишуть про злиття виключно як про складову рекурсивного сортування злиттям, тоді як тут потрібне \emph{сам\'{е} злиття, без} рекурсивної надбудови сортування. Крім того, не\nolinebreak[3] всі алгоритми, які правильно виконують стандартне злитя, однаково легко модифікуються на вибір лише спільних.

\MyParagraph{Навіщо в умові згадані групи тестів зі значеннями до 12345?}
Щоб надати можливість набрати ще~${\approx}20$~балів тим, хто не~додумався ні до одного з розглянутих правильних способів, але\nolinebreak[3] знає наступний, зі складністю $O(N{\cdot}M\dib{{+}}V)$, де\nolinebreak[3] $V$\nolinebreak[3] --- діапазон значень. (Мається на увазі організувати програму як <<\texttt{if} (розміри малі) \texttt{then} (вирішити способом згаданим на самому початку розбору) \texttt{else} (вирішити описаним далі способом)>>. Вхідні дані, коли великі одночасно і\nolinebreak[3] кількості, і\nolinebreak[3] значення, такий розв'язок все\nolinebreak[3] одно не\nolinebreak[3] пройде, але можливо набере трохи більше балів.)

Так от, у\nolinebreak[3] випадках, коли значення малі, досить ефективний такий підхід. Заведемо масив, \emph{індексами} якого будуть \emph{значення} зі\nolinebreak[3] вхідних даних, щоб щоразу, прочитавши деяке~\texttt{v}, збільшувати\nolinebreak[2] \texttt{num[v]}\nolinebreak[2] на~1 (а~спочатку всі значення\nolinebreak[3] \texttt{num[$\cdot$]} ініціалізуються нулями). Таким чином, після обробки усього двовимірного вхідного масиву кожне значення\nolinebreak[2] \texttt{num[v]} означатиме, скільки разів зустрілося число~\texttt{v}; оскільки у\nolinebreak[3] кожному окремо взятому рядку всі ч\'{и}сла різні, то <<число~\texttt{v} зустрілося в усіх рядках>> рівносильно\nolinebreak[1] \mbox{\texttt{num[v]=N}}.

\MyParagraph{Чому реалізація правильного алгоритму мовою\nolinebreak[3] C++ не~вкладається в обмеження часу?}Звісно, це можуть бути технічні помилки. Але ще є такий сумний факт, що введення/\nolinebreak[2]виведення засобами \texttt{istream}/\nolinebreak[2]\texttt{ostream} (зокрема, \texttt{cin}/\nolinebreak[2]\texttt{cout}) працює повільно. Настільки повільно, що перевищувати час буде саме лише читання, взагалі без обробки по~суті. Вихід\nolinebreak[3] --- читати функцією \texttt{scanf}, яка з незвички може здаватися незруч\-ною, зате швидко працює. І\nolinebreak[3] взагалі, є дуже вже багато моментів, коли C++ виграє у Паскаля; тож окремі ситуації, коли неграмотне використання~С++ призводить до результатів гірших, ніж Паскаль, можна вважати проявом справедливості\dots
